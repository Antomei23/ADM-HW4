{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4 - Recommendation systems and clustering everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Analyzing e fixing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = \"vodclickstream_uk_movies_03.csv\"\n",
    "\n",
    "Netflix = pd.read_csv(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 671736 entries, 0 to 671735\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Unnamed: 0    671736 non-null  int64  \n",
      " 1   datetime      671736 non-null  object \n",
      " 2   duration      671736 non-null  float64\n",
      " 3   title         671736 non-null  object \n",
      " 4   genres        671736 non-null  object \n",
      " 5   release_date  671736 non-null  object \n",
      " 6   movie_id      671736 non-null  object \n",
      " 7   user_id       671736 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 41.0+ MB\n"
     ]
    }
   ],
   "source": [
    "Netflix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change datetime in this way, we can work with this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix.datetime = pd.to_datetime(Netflix.datetime)\n",
    "Netflix.release_date = pd.to_datetime(Netflix.release_date, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Will use an LSH algorithm and to use it we need shingles, so we will change he \"genres\" features in a way ta√¨hat we can access to each genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix.genres.apply(lambda row: row.split(','))\n",
    "Netflix['genres_list'] = ''\n",
    "Netflix['genres_list'] = Netflix.genres.apply(lambda row: [word.strip() for word in row.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004e2862</td>\n",
       "      <td>Hannibal</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Looper</td>\n",
       "      <td>Action, Drama, Sci-Fi, Thriller</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Frailty</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure, Comedy, Family, Fantasy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>Resident Evil</td>\n",
       "      <td>Action, Horror, Sci-Fi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id          title                              genres  clicks\n",
       "0  00004e2862       Hannibal              Crime, Drama, Thriller       1\n",
       "6  000052a0a0         Looper     Action, Drama, Sci-Fi, Thriller       9\n",
       "3  000052a0a0        Frailty              Crime, Drama, Thriller       3\n",
       "5  000052a0a0        Jumanji  Adventure, Comedy, Family, Fantasy       3\n",
       "7  000052a0a0  Resident Evil              Action, Horror, Sci-Fi       2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We add the clicks feature to know how many time each user watched that film, in this way we don't lose the info of which film\n",
    "#each user wathced a lot of times\n",
    "Netflix['clicks'] = 1\n",
    "user_clicks = Netflix.groupby(['user_id', 'title', 'genres']).size().reset_index(name='clicks')\n",
    "\n",
    "# Sort the DataFrame by clicks in descending order for each user\n",
    "user_clicks_sorted = user_clicks.sort_values(by=['user_id', 'clicks'], ascending=[True, False])\n",
    "\n",
    "# Group by user_id and take the top 10 movies for each user\n",
    "top_10_movies_per_user = user_clicks_sorted.groupby('user_id').head(10)\n",
    "\n",
    "# Display the result (title, genres_list, and clicks of the top 10 movies for each user)\n",
    "top_10_movies_per_user[['user_id', 'title', 'genres', 'clicks']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want a matrix that remind which genre each user watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = set(genre for genres_list in Netflix['genres_list'] for genre in genres_list)# avoid doubles\n",
    "all_genres=list(all_genres)\n",
    "all_user_ids = Netflix['user_id'].unique()\n",
    "matrix2 = pd.DataFrame(0, index=all_genres, columns=all_user_ids)\n",
    "\n",
    "# We put a 1 if the user saw a film of that type\n",
    "for index, row in Netflix.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    genres_list = row['genres_list']\n",
    "    matrix2.loc[genres_list, user_id] = 1\n",
    "\n",
    "#matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Minhash Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to simulate the permutation od the rows, to do it we use an hash function that we will be fixed after the start of the procedure. this is a procedure that we need to create a signature Matrix, also To reduce the number of calculation and comparison we want to create a signature matrix and divide this in band, we will use numpy to speed-up all the procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(x,m,a,b):\n",
    "  p=31\n",
    "  c=((a*x+b)%p)\n",
    "  return(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "k = 19\n",
    "num_rows = matrix2.shape[0]\n",
    "\n",
    "#we choose the parameter of the hash formula\n",
    "a = [random.randint(1, 100) for _ in range(k+1)]\n",
    "b = [random.randint(1, 100) for _ in range(k+1)]\n",
    "#initialization of the signature matrix\n",
    "Signature_hash = np.full((k+1, len(all_user_ids)), 10000)\n",
    "m=-1#temporary number that we need because the resulting matrix will be a numpy\n",
    "for j in all_genres:\n",
    "    m+=1\n",
    "    s=-1 #same reason of m\n",
    "    for h in all_user_ids:\n",
    "        s+=1\n",
    "        if matrix2.loc[j, h] == 1:\n",
    "\n",
    "          for i in range(k+1):\n",
    "            #we choosed to keep the min value, like in the paper that was proposed in the HW\n",
    "            Signature_hash[i,s]=min(hash_function(m,113,a[i],b[i]),Signature_hash[i,s])\n",
    "\n",
    "\n",
    "\n",
    "#Signature_hash\n",
    "#to work again with the user_ids we want the matrix like a Dataframe\n",
    "Signature_hash_df = pd.DataFrame(Signature_hash, index=range(k+1), columns=all_user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 LSH Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSH is the combination of the following passages, now the important thing is in how many buckets we want to divide the users. We used this parameters for the buckets, bands because after we tried a lot we found that this was a good compromise for to obtain a good solution in a good amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Band\n",
    "#we want to divide the band to reduce the number of comparison, we know that more rows will mean an higher\n",
    "#precision but we will have an higher cost of calculation\n",
    "rows_per_band = 5\n",
    "num_bands = k // rows_per_band\n",
    "\n",
    "buckets = {}\n",
    "\n",
    "for band_index in range(num_bands+1):\n",
    "  n = [random.randint(1, 100) for _ in range(rows_per_band+1)]\n",
    "\n",
    "  for i in all_user_ids:\n",
    "    hash_values=0\n",
    "    # isolatung the column and the rows\n",
    "    start_row = band_index * rows_per_band\n",
    "    end_row = ((band_index + 1) * rows_per_band)-1\n",
    "    v=Signature_hash_df.loc[start_row:end_row,i]\n",
    "    #we hash again this value and we will use it like a key for a dictionary, in this\n",
    "    #way we can divide the users, the users in the same bucket will be more similar\n",
    "    for g in range(len(v)):\n",
    "      hash_values+=v[g+band_index * rows_per_band]*n[g]\n",
    "    hash_values=hash_values%41\n",
    "    if hash_values not in buckets:\n",
    "      buckets[hash_values] = []\n",
    "    buckets[hash_values].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the Similarity with the Jaccard Similarity,\n",
    "so number of buckets were both users are present divided by the number of buckets where it is present alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(user1, user2):\n",
    "\n",
    "    counter=0#we need this to calculate in how many buckets that they are present\n",
    "    key=buckets.keys()\n",
    "    for s in key:\n",
    "      if user1 in buckets[s] and user2 in buckets[s]:\n",
    "        counter+=1\n",
    "    similarity_value=counter/(num_bands+1)\n",
    "\n",
    "    return similarity_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the 2 user more similar to one we will use the function described before iterating it on all the users of the same buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_most_similar(user):\n",
    "    v = []\n",
    "    key=buckets.keys()\n",
    "    for k in key:\n",
    "        if user in buckets[k]:\n",
    "            # We don't want to calculate the similarity with each other user, but only with the users of the same bucket\n",
    "            for h in buckets[k]:\n",
    "                if h != user:\n",
    "                    sim = similarity(user, h)\n",
    "                    v.append((h, sim))\n",
    "\n",
    "    # Ordering with the higher similarity\n",
    "    v=list(set(v))\n",
    "    sorted_list = sorted(v, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # We need only the best 2\n",
    "    best = sorted_list[:2]\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Raccomandation(user):\n",
    "  #2 temporary variable\n",
    "  clicks1=[]\n",
    "  clicks2=[]\n",
    "\n",
    "  best=two_most_similar(user)#finding the most 2 similar users to the one we are searching\n",
    "  users,sim=zip(*best)\n",
    "  users_list=list(users)\n",
    "  #we take the film for each user\n",
    "  movies_for_user1 = top_10_movies_per_user.loc[top_10_movies_per_user['user_id'] == users_list[0], 'title']\n",
    "  movies_for_user2 = top_10_movies_per_user.loc[top_10_movies_per_user['user_id'] == users_list[1], 'title']\n",
    " #first we want the movies that they have in common\n",
    "  tip=list(set(movies_for_user1).intersection(set(movies_for_user2)))\n",
    "\n",
    "  if len(tip)<5: #if we haven't enough film\n",
    "\n",
    "    temp_v = set(movies_for_user1) - set(tip) #we take the film that are diffirent for fist user\n",
    "    temp_v = pd.Series(list(temp_v))\n",
    "    #the following passages are to order in base of clicks\n",
    "    for g in temp_v:\n",
    "      clicks1.append(top_10_movies_per_user.loc[(top_10_movies_per_user['user_id'] == users_list[0]) & (top_10_movies_per_user['title'] == g),'clicks'].values)\n",
    "    temp=zip(temp_v,clicks1)\n",
    "    best_df = pd.DataFrame(temp, columns=['title', 'clicks'])\n",
    "    best = best_df.sort_values(by='clicks', ascending=False).head(5)\n",
    "    a=5-len(tip) #a indicates the film that i am missing\n",
    "    if a<= len(best): #now we have enough films\n",
    "      raccomandation=best[:a]\n",
    "      titles=raccomandation['title'].tolist()\n",
    "      final=tip+titles\n",
    "    else: #we still haven't enough films\n",
    "      titles=best['title'].tolist()\n",
    "      final = list(tip) + list(titles)\n",
    "       #we repeat the same process that we did for the first user to the second user\n",
    "      temp_2 = list(set(movies_for_user2) - set(tip))\n",
    "\n",
    "      for g in temp_2:\n",
    "        clicks2.append(top_10_movies_per_user.loc[(top_10_movies_per_user['user_id'] == users_list[1]) & (top_10_movies_per_user['title'] == g),'clicks'].values)\n",
    "      temp=zip(temp_2,clicks2)\n",
    "      best_df = pd.DataFrame(temp, columns=['title', 'clicks'])\n",
    "      best = best_df.sort_values(by='clicks', ascending=False)\n",
    "      a=5-len(final)\n",
    "      raccomandation=best[:a] \n",
    "\n",
    "      titles2=raccomandation['title'].tolist()\n",
    "      final=final+titles2\n",
    "\n",
    "\n",
    "  elif len(tip)>6: #we have too much film , so we order for the click and then take only the best one\n",
    "    for h in tip:\n",
    "      clicks.append(top_10_movies_per_user.loc[(top_10_movies_per_user['user_id'] == users_list[0]) & (top_10_movies_per_user['title'] == h), 'clicks']+top_10_movies_per_user.loc[(top_10_movies_per_user['user_id'] == users_list[1])& (top_10_movies_per_user['title'] == h), 'clicks'])\n",
    "    temp=zip(tip,clicks)\n",
    "    best_df = pd.DataFrame(temp, columns=['title', 'clicks'])\n",
    "    best = best_df.sort_values(by='clicks', ascending=False).head(5)\n",
    "    titles=best['title'].tolist()\n",
    "    final = list(tip) + list(titles)\n",
    "\n",
    "  return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Christmas Inheritance',\n",
       " 'A Christmas Prince',\n",
       " 'Fallen',\n",
       " 'Budapest',\n",
       " 'Deadly Scholars']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query=Raccomandation('2428de4ee1')\n",
    "Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Command Line Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The executable script file and the output screen can be found in the repository under the name CommandLine.sh and CommandLine.png. Below I put the text of the file for easier reading and understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "input_file=\"vodclickstream_uk_movies_03.csv\"\n",
    "\n",
    "# 1. What is the most-watched Netflix title?\n",
    "# group by the uniques titles and count the number of occurrences, saving them in a txt file\n",
    "awk -F ',' '{print $4}' $input_file | sort | uniq -c | sort -nr > title_count.txt\n",
    "# get the title from the txt file\n",
    "most_watched_title=$(head -n 1 title_count.txt | awk '{$1=\"\"; print $0}' | sed 's/^ *//')\n",
    "echo \"Most watched title: $most_watched_title\"\n",
    "\n",
    "# 2. The average time of subsequent clicks on Netflix.com\n",
    "# filtering the duration tha has to be >= 0.0 and saving the values in a new file\n",
    "awk -F ',' '{ if ($3 >= 0.0) print $0 }' $input_file > filtered_duration.csv\n",
    "# the sum of duration (column 3) and the average of them\n",
    "avg_duration=$(awk -F ',' '{print $3}' filtered_duration.csv | awk '{sum += $1} END {print sum/NR}')\n",
    "# convert the duration from seconds to minutes\n",
    "avg_min=$(awk -v avg_duration=\"$avg_duration\" 'BEGIN { avg_min = avg_duration / 60; printf \"%.2f\\n\", avg_min }')\n",
    "# print the result\n",
    "echo \"Average duration of subsequent clicks: $avg_min minutes\"\n",
    "\n",
    "# 3. ID of the user that has spent the most time on Netflix\n",
    "# group by the user_id and sum the duration time of each user, then sorting them and saving them in a txt file\n",
    "awk -F ',' 'NR>1 { sum[$NF] += $3 } END { for (i in sum) print i, sum[i] }' filtered_duration.csv | sort -k2,2nr > sorted_users.txt\n",
    "# get the user_id from the txt file\n",
    "high_time_user=$(head -n 1 sorted_users.txt | awk '{print $1}')\n",
    "echo \"The user that has spent the most time on Netflix: $high_time_user\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To get the most watched Netflix title, we first grouped by each title in the dataset, then counted each time this appeared and saved the results in descending order in a new file, called ```title_count.txt```. At the end we extracted the first title of the file previusly created.\n",
    "2. The average time of subsequent clicks on Netflix, we interpreted it as the average of all the duration times in the column 'duration' of the dataset, since it represents how much time the user stayed on the title, so each value corresponds to one click. Sais this, we filtered the dataset taking into account only the durations that are not negative, then summed all the remaining and took the average. Finally we converted the result from seconds to minutes.\n",
    "3. The id of the user that has spent the most time on netflix has been extracted by first grouping the dataset by each user id, then summing the durations of each one and sorting them in descending order in a file, called ```sorted_users.txt```. At the end we extracted the first user in the file just created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CommandLine](CommandLine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Algorithmic Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He was given an initial personal score of when he enrolled ***S***, which changes every time he takes an exam.\\\n",
    "Every of the exams he has to take is assigned a mark ***p***.\\\n",
    "Once he has chosen an exam, his score becomes equal to the mark **S = p**, and at the same time, the scoring system changes:\n",
    "- If he takes an \"easy\" exam (the score of the exam being less than his score), every other exam's mark is increased by\n",
    "the quantity **$S-p$**.\n",
    "- If he takes a \"hard\" exam (the score of the exam is greater than his score), every other exam's mark is decreased by\n",
    "the quantity **$p-S$**.\n",
    "- The exam score can't be negative, so if in any update a mark goes below zero it must be collapsed to zero.\n",
    "\n",
    "He wants to know which is the highest score possible he could get.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedericosScore(S, marks, p):\n",
    "\n",
    "    copy_marks = marks.copy()                                             # T(n)\n",
    "\n",
    "    if len(copy_marks) == 1:   # base case                                # T(1)\n",
    "        return copy_marks[0]                                              \n",
    "\n",
    "    if p <= S: # easy exam                                                # T(1)\n",
    "        copy_marks.pop(0)                                                 # T(n)\n",
    "        copy_marks = [x+(S-p) if x+(S-p)>=0 else 0 for x in copy_marks]   # T(n) \n",
    "        S = p                                                             # T(1)\n",
    "\n",
    "    else: # hard exam                                                     # T(n)\n",
    "        copy_marks.pop(0)\n",
    "        copy_marks = [x-(p-S) if x-(p-S) >= 0 else 0 for x in copy_marks] #T(n) \n",
    "        S = p\n",
    "        \n",
    "    return FedericosScore(S, copy_marks, copy_marks[0])                   # T(n-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score Federico can get is: 11 with this oder: [7, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "# input 1\n",
    "S = 8\n",
    "marks = [5, 7, 1]\n",
    "\n",
    "permutations = [list(x) for x in itertools.permutations(marks, len(marks))] # all the possible permutations of the exams O(n!)\n",
    "\n",
    "scores = {}\n",
    "for permu in permutations:\n",
    "    scores[FedericosScore(S=S, marks=permu, p=permu[0])] = permu\n",
    "max_s = max(scores.keys())\n",
    "print(f'The highest score Federico can get is: {max_s} with this oder: {scores[max_s]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score Federico can get is: 44 with this order: [27, 21, 32, 18, 24]\n"
     ]
    }
   ],
   "source": [
    "# input 2\n",
    "S = 25\n",
    "marks = [18, 24, 21, 32, 27]\n",
    "\n",
    "#FedericosScore(S, marks, marks[0])\n",
    "\n",
    "permutations = [list(x) for x in itertools.permutations(marks, len(marks))] # all the possible permutations of the exams \n",
    "\n",
    "scores = {}\n",
    "for permu in permutations:\n",
    "    scores[FedericosScore(S=S, marks=permu, p=permu[0])] = permu\n",
    "max_s = max(scores.keys())\n",
    "print(f'The highest score Federico can get is: {max_s} with this order: {scores[max_s]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 3\n",
    "S = 30\n",
    "marks = [13, 27, 41, 59, 28, 33, 39, 19, 52, 48, 55, 79]\n",
    "\n",
    "permutations = [list(x) for x in itertools.permutations(marks, len(marks))] # all the possible permutations of the exams \n",
    "\n",
    "# memory exceeded\n",
    "\n",
    "scores = {}\n",
    "for permu in permutations:\n",
    "    scores[FedericosScore(S=S, marks=permu, p=permu[0])] = permu\n",
    "max_s = max(scores.keys())\n",
    "print(f'The highest score Federico can get is: {max_s} with this order: {scores[max_s]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind this initial solution is to have a function, ```FedrericosScore```, that takes in input:\n",
    "- ```S```: the initial score of the student\n",
    "- ```marks```: the list of the exams' marks\n",
    "- ```p```: the first exam's mark\n",
    "\n",
    "Then, since the student can choose the order of the esams he can take, we compute all the possible $n!$ permutations of the exams and give them in input, one by one, to the function.\\\n",
    "The result will be stored in a dictionary with keys the score and as vaulues the specific permutation that will make the student obstain that final score.\\\n",
    "Finally, we take the maximum score, out of the dictionary's keys, and its associated value; in this way the student will know in which order he has to take its exams in order to obtain the maximum score possible.\n",
    "\n",
    "time complexity of the function:\\\n",
    "Assuming $n$ is the lenght of the ```marks``` list\n",
    "- ```copy_marks``` has a time complexity of $T(n)$\n",
    "- ```if len(copy_marks) == 1``` has a constant time complexity $T(1)$\n",
    "- ```if p <= S:``` has a total time complexity of $T(n)$, since it has to pop the first element, shifting all the others, and in the list comprehension has to iterate on all the elements of the list.\n",
    "- ```else:``` has a total time complexity of $T(n)$ for the same reason above.\n",
    "- ```return FedericosScore``` has a time complexity of $T(n-1)$ in the worst case, since depends on the number of elements left in the list.\n",
    "\n",
    "The total running time $T(n)$ can be expressed as:\n",
    "\\begin{align*}\n",
    "T(n) =\n",
    "\\begin{cases} \n",
    "n+1 & \\text{ if $n = 1$} \\\\\n",
    "T(n-1)+5n+1 & \\text{ if $n>1$} \n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "Generalizing we'll have a $T(n-i)+(5 \\cdot i)n + i$, which at the end will result in $T(n) = 5n^2 - 3n + 2 \\implies O(n^2)$.  \n",
    "\n",
    "So the function has a quadratic time complexity of $O(n^2)$, then it has to be applied $n!$ times, for each one of the permutations of the list, so at the end the whole algorithm will have a complexity of $O(n^2 \\cdot n!)$\n",
    "\n",
    "This can't be sustainbable, since is highly memory-comsuming computing all the $n!$ permutations of a list as $n$ grows; for this reason this method doesn't work on the ```intput 3``` since has $n=12$ elements and all its permutations will be $479.001.600$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Federicos_score_opt(S, marks):\n",
    "\n",
    "    if len(marks) == 0:                                                                # T(1)     \n",
    "        return S                                                                       # T(1)     \n",
    "    \n",
    "    maxScore = 0  # keep track of the maximum score Federico can achieve               # T(1)\n",
    "    for i, mark in enumerate(marks):                                                   # T(n) \n",
    "        update_marks = marks[:i] + marks[i+1:] # don't consider the current exam       # T(n) \n",
    "        newScore = mark                                                                # T(1)\n",
    "        if mark <= S: # esasy exam                                                     # T(1)\n",
    "            update_marks = [x+(S-mark) if x+(S-mark)>=0 else 0 for x in update_marks]  # T(n)\n",
    "        else: # hard exam\n",
    "            update_marks = [x-(mark-S) if x-(mark-S)>=0 else 0 for x in update_marks]  # T(n)\n",
    "\n",
    "        # comparing the current maxScore with the result of the recursive call.\n",
    "        maxScore = max(maxScore, Federicos_score_opt(newScore, update_marks))          # T(n-1)\n",
    "    return maxScore                                                                    # T(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: 11\n"
     ]
    }
   ],
   "source": [
    "# input 1\n",
    "S_1 = 8\n",
    "p_1 = [5, 7, 1]\n",
    "result_1 = Federicos_score_opt(S_1, p_1)\n",
    "print(\"Output 1:\", result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 2: 44\n"
     ]
    }
   ],
   "source": [
    "S_2 = 25\n",
    "p_2 = [18, 24, 21, 32, 27]\n",
    "result_2 = Federicos_score_opt(S_2, p_2)\n",
    "print(\"Output 2:\", result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 3: 109\n"
     ]
    }
   ],
   "source": [
    "S_3 = 30\n",
    "p_3 = [13, 27, 41, 59, 28, 33, 39, 19, 52, 48, 55, 79]\n",
    "result_3 = Federicos_score_opt(S_3, p_3)\n",
    "print(\"Output 3:\", result_3)\n",
    "\n",
    "# took 16 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this solution we don't have to explicitally compute all the possible permutations of the exams, because the optimized function explores all possible combinations of the exams recursivly and eventually finds the combination that guarantees the highest score possible by exploring different paths for each exam in the list. \n",
    "\n",
    "Time complexity of the function:\\\n",
    "Assuming $n$ is the lenght of the ```marks``` list\n",
    "- ```if len(copy_marks) == 1``` has a constant time complexity $T(1)$\n",
    "- ```for i, mark in enumerate(marks)``` has a linear time of $T(n)$ because we iterate through all the exams\n",
    "- ```update_marks = marks[:i] + marks[i + 1:]``` has a linear time complexity $T(n)$ since we're performing a list slicing\n",
    "- ```if mark <= S``` loop has a total complexity of $T(n)$ since the list comprehension inside explores all the elements in the list\n",
    "- ```else``` loop has the complexity of $T(n)$ for the same reason above\n",
    "- ```maxScore = max(maxScore, Federicos_score_opt(newScore, update_marks))``` has a time complexity of $T(n-1)$ in the worst case, since depends on the number of elements left in the list.\n",
    "\n",
    "Since the recursive call of the function is inside the loop of complexity $O(n^2)$, this significantly contributes to the overall complexity of the function, that is $O(n^3)$.\\\n",
    "This is an improvement in respect to the previus algorithm, both on time complexity and memory complexity, since we're now able to actually see a result for the exam's list of the third input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT optimization implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Federicos_score_chatGPT(S, marks, store={}):\n",
    "    if len(marks) == 0:\n",
    "        return S\n",
    "\n",
    "    if (S, tuple(marks)) in store:\n",
    "        return store[(S, tuple(marks))]\n",
    "\n",
    "    maxScore = 0\n",
    "    for i, mark in enumerate(marks):\n",
    "        update_marks = marks[:i] + marks[i + 1:]\n",
    "        newScore = mark\n",
    "        if mark <= S:\n",
    "            update_marks = [x + (S - mark) if x + (S - mark) >= 0 else 0 for x in update_marks]\n",
    "        else:\n",
    "            update_marks = [x - (mark - S) if x - (mark - S) >= 0 else 0 for x in update_marks]\n",
    "\n",
    "        maxScore = max(maxScore, Federicos_score_chatGPT(newScore, update_marks, store))\n",
    "\n",
    "    store[(S, tuple(marks))] = maxScore\n",
    "    return maxScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: 11\n"
     ]
    }
   ],
   "source": [
    "# input 1\n",
    "S_1 = 8\n",
    "p_1 = [5, 7, 1]\n",
    "result_1 = Federicos_score_chatGPT(8, [5,7,1])\n",
    "print(\"Output 1:\", result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 2: 44\n"
     ]
    }
   ],
   "source": [
    "S_2 = 25\n",
    "p_2 = [18, 24, 21, 32, 27]\n",
    "result_2 = Federicos_score_chatGPT(S_2, p_2)\n",
    "print(\"Output 2:\", result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 3: 109\n"
     ]
    }
   ],
   "source": [
    "S_3 = 30\n",
    "p_3 = [13, 27, 41, 59, 28, 33, 39, 19, 52, 48, 55, 79]\n",
    "result_3 = Federicos_score_chatGPT(S_3, p_3)\n",
    "print(\"Output 3:\", result_3)\n",
    "\n",
    "# took 2.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Approach:\n",
    "\n",
    "- **Memoization**: Introduced a memoization dictionary (```store```) to store previously computed results for combinations of ```S``` and ```marks```. This prevents redundant calculations by checking if a specific combination has been encountered before. If so, it retrieves the result from memo instead of recomputing it.\n",
    "\n",
    "- **Avoidance of Recomputation**: By storing and retrieving results from the ```store``` dictionary, the function bypasses the need to recompute solutions for the same combination of ```S``` and ```marks```. This significantly reduces the number of recursive calls and computations required, leading to a more efficient algorithm overall.\n",
    "\n",
    "This optimization effectively reduces the time complexity of the algorithm from $O(n^3)$ to $O(n^2)$ by avoiding redundant computations through memoization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
